Tara: 
data analysis codes to create graph 
Tool Used: google colab (scatter bubble plot)

#importing relevant libraires
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#upload file to database
df = pd.read_excel('/content/Homeless 2024.xlsx')

#checking correct dataset is uploaded 
df.head() 

#Top 50 locations with the highest homeless population
top_50_df = df.nlargest(50, "Homeless Population")

# numeric index for plotting
top_50_df["Location_Index"] = range(len(top_50_df))

# Create the graph
plt.figure(figsize=(18, 10))
scatter = plt.scatter(top_50_df["Location_Index"], top_50_df["Homeless Population"],
                      s=top_50_df["BubbleSize"], alpha=0.5, c=top_50_df["Homeless Population"],
                      cmap="coolwarm", edgecolors="black")

# Set x-ticks for only the top 50 locations
plt.xticks(top_50_df["Location_Index"], top_50_df["Location"], rotation=65, fontsize=7) #angle of location names and size

# Add labels and title to the graph
plt.title("Top 50 UK Local Authorities by Homeless Population (2024)")
plt.xlabel("Location")
plt.ylabel("Homeless Population")
plt.colorbar(label="Homeless Population")  #adds colour bar on side

# Show the plot and display
plt.show()







OMAR:
Data cleaning and preparation of the 'Household Deprivation' dataset
Tool used: Google Colab

# importing necessary libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# loading the dataset and printing each sheet name
df = pd.read_excel('/content/Household Deprivation.xlsx')
xls = pd.ExcelFile('/content/Household Deprivation.xlsx')
print(xls.sheet_names)

# Preview the data for only the first sheet
Sheet1 = pd.read_excel('/content/Household Deprivation.xlsx', sheet_name='Dataset')
Sheet1.head()

# Preview the data for only the second sheet
Sheet2 = pd.read_excel('/content/Household Deprivation.xlsx', sheet_name='Metadata')
Sheet2.head()

# Checking the data types
Sheet1.info()

# Checking for missing values
Sheet1.isnull()

# Plotting a heatmap of missing values
cols = Sheet1.columns
plt.figure(figsize = (10,5))
sns.heatmap(Sheet1[cols].isnull())

# Checking percentage of missing values for each column
missing_pct = round(Sheet1.isnull().sum()/len(df)*100,1)
print(missing_pct)

# Dropping a specific column
for sheet in xls.sheet_names:
    df = pd.read_excel(xls, sheet_name=sheet)
    columns_to_drop = ['Household deprivation (6 categories) Code']
    columns_to_drop = [col for col in columns_to_drop if col in df.columns]

    if columns_to_drop:
            df = df.drop(columns=columns_to_drop)
            print(f"Dropped columns: {columns_to_drop}")

    df.fillna(df.mode().iloc[0], inplace=True)
    print(f'Updated data for sheet {sheet}:')
    print(df)
    print()
    df.head()

# Dropping the second sheet and saving the new cleaned file only containing the first sheet
file_path = "/content/Household Deprivation.xlsx"
xls = pd.ExcelFile(file_path)
sheet_to_drop = "Metadata"
all_sheets = xls.sheet_names
sheets_dict = {sheet: xls.parse(sheet) for sheet in all_sheets if sheet != sheet_to_drop}
output_path = "cleaned_Household_Deprivation.xlsx"
with pd.ExcelWriter(output_path) as writer:
    for sheet, df in sheets_dict.items():
        df.to_excel(writer, sheet_name=sheet, index=False)
